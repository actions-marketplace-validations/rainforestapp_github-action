on: push

jobs:
  test:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
    steps:
      - uses: actions/checkout@v2
      - name: Install faketime
        run: |
          sudo apt-get update
          sudo apt-get install libfaketime
      - name: Base case command
        id: test_base
        uses: ./
        env:
          LD_PRELOAD: /usr/lib/x86_64-linux-gnu/faketime/libfaketime.so.1
          FAKETIME: 2021-12-31 23:59:59
        with:
          token: test_token
          run_group_id: 42
          dry_run: true
      - name: Base case test
        env:
          EXPECTED_COMMAND: run --skip-update --token test_token --run-group 42 --junit-file results/rainforest/junit.xml --save-run-id .rainforest_run_id --description 'rainforestapp/github-action - ${{ github.ref_name }} test 2021-12-31T23:59:59Z' --release '${{ github.sha }}'
        run: |
          if [ "${{ steps.test_base.outputs.command }}" != "${EXPECTED_COMMAND}" ] ; then
            echo "::error ::expected ${{ steps.test_base.outputs.command }} to equal ${EXPECTED_COMMAND}"
            exit 1
          fi
      - name: All parameters command
        id: test_all_parameters
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          description: foo
          environment_id: 117
          conflict: abort-all
          crowd: automation
          release: '1.0'
          background: true
          dry_run: true
      - name: All parameters test
        env:
          EXPECTED_COMMAND: run --skip-update --token test_token --run-group 42 --junit-file results/rainforest/junit.xml --save-run-id .rainforest_run_id --conflict abort-all --environment-id 117 --crowd automation --description 'foo' --release '1.0' --background
        run: |
          if [ "${{ steps.test_all_parameters.outputs.command }}" != "${EXPECTED_COMMAND}" ] ; then
            echo "::error ::expected ${{ steps.test_all_parameters.outputs.command }} to equal ${EXPECTED_COMMAND}"
            exit 1
          fi
      - name: Custom URL command
        id: test_custom_url
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          description: foo
          custom_url: https://something.com
          release: '1.0'
          dry_run: true
      - name: Custom URL test
        env:
          EXPECTED_COMMAND: run --skip-update --token test_token --run-group 42 --junit-file results/rainforest/junit.xml --save-run-id .rainforest_run_id --custom-url https://something.com --description 'foo' --release '1.0'
        run: |
          if [ "${{ steps.test_custom_url.outputs.command }}" != "${EXPECTED_COMMAND}" ] ; then
            echo "::error ::expected ${{ steps.test_custom_url.outputs.command }} to equal ${EXPECTED_COMMAND}"
            exit 1
          fi
      - name: Environment ID and Custom URL command
        id: test_environment_id_custom_url
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          description: foo
          environment_id: 117
          custom_url: https://something.com
          release: '1.0'
          dry_run: true
      - name: Environment ID and Custom URL test
        env:
          EXPECTED_COMMAND: run --skip-update --token test_token --run-group 42 --junit-file results/rainforest/junit.xml --save-run-id .rainforest_run_id --custom-url https://something.com --description 'foo' --release '1.0'
        run: |
          if [ "${{ steps.test_environment_id_custom_url.outputs.command }}" != "${EXPECTED_COMMAND}" ] ; then
            echo "::error ::expected ${{ steps.test_environment_id_custom_url.outputs.command }} to equal ${EXPECTED_COMMAND}"
            exit 1
          fi
      - name: Missing token command
        id: test_missing_token
        uses: ./
        with:
          dry_run: true
        continue-on-error: true
      - name: Missing token test
        run: |
          if [ "${{ steps.test_missing_token.outcome }}" != 'failure' ] ; then
            echo "::error ::expected ${{ steps.test_missing_token.outcome }} to equal failure"
            exit 1
          fi
          if [ "${{ steps.test_missing_token.outputs.error }}" != 'Token not set' ] ; then
            echo "::error ::expected ${{ steps.test_missing_token.outputs.error }} to equal Token not set"
            exit 1
          fi
      - name: Invalid run group command
        id: test_invalid_run_group
        uses: ./
        with:
          token: test_token
          run_group_id: nike
          dry_run: true
        continue-on-error: true
      - name: Invalid run group test
        run: |
          if [ "${{ steps.test_invalid_run_group.outcome }}" != 'failure' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_run_group.outcome }} to equal failure"
            exit 1
          fi
          if [ "${{ steps.test_invalid_run_group.outputs.error }}" != 'run_group_id not a positive integer (nike)' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_run_group.outputs.error }} to equal run_group_id not a positive integer (nike)"
            exit 1
          fi
      - name: Invalid environment ID command
        id: test_invalid_environment_id
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          environment_id: hostile
          dry_run: true
        continue-on-error: true
      - name: Invalid environment ID test
        run: |
          if [ "${{ steps.test_invalid_environment_id.outcome }}" != 'failure' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_environment_id.outcome }} to equal failure"
            exit 1
          fi
          if [ "${{ steps.test_invalid_environment_id.outputs.error }}" != 'environment_id not a positive integer (hostile)' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_environment_id.outputs.error }} to equal environment_id not a positive integer (hostile)"
            exit 1
          fi
      - name: Invalid conflict command
        id: test_invalid_conflict
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          conflict: WWIII
          dry_run: true
        continue-on-error: true
      - name: Invalid conflict test
        run: |
          if [ "${{ steps.test_invalid_conflict.outcome }}" != 'failure' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_conflict.outcome }} to equal failure"
            exit 1
          fi
          if [ "${{ steps.test_invalid_conflict.outputs.error }}" != 'WWIII not in (abort abort-all)' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_conflict.outputs.error }} to equal WWIII not in (abort abort-all)"
            exit 1
          fi
      - name: Invalid crowd command
        id: test_invalid_crowd
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          crowd: hipsters
          dry_run: true
        continue-on-error: true
      - name: Invalid crowd test
        run: |
          if [ "${{ steps.test_invalid_crowd.outcome }}" != 'failure' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_crowd.outcome }} to equal failure"
            exit 1
          fi
          if [ "${{ steps.test_invalid_crowd.outputs.error }}" != 'hipsters not in (default automation automation_and_crowd on_premise_crowd)' ] ; then
            echo "::error ::expected ${{ steps.test_invalid_crowd.outputs.error }} to equal hipsters not in (default automation automation_and_crowd on_premise_crowd)"
            exit 1
          fi
      - name: Rerun test setup
        run: |
          echo "343" > .rainforest_run_id
      - name: Rerun command
        id: test_rerun
        uses: ./
        with:
          token: test_token
          run_group_id: 42
          environment_id: 117
          description: foo
          conflict: abort
          crowd: automation
          release: '1.0'
          background: true
          dry_run: true
      - name: Rerun test
        env:
          EXPECTED_COMMAND: rerun 343 --skip-update --token test_token --junit-file results/rainforest/junit.xml --save-run-id .rainforest_run_id --conflict abort --release '1.0' --background
        run: |
          if [ "${{ steps.test_rerun.outputs.command }}" != "${EXPECTED_COMMAND}" ] ; then
            echo "::error ::expected ${{ steps.test_rerun.outputs.command }} to equal ${EXPECTED_COMMAND}"
            exit 1
          fi
